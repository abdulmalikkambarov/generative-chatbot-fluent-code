{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#1 Mounting the Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX79cgdEoR3G",
        "outputId": "29e87a12-3877-449e-c7bb-8460729fe8d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2RjUhNsqY4L"
      },
      "source": [
        "import re\n",
        "import random\n",
        "data_path = \"/content/sample_data/human_text.txt\"\n",
        "data_path2 = \"/content/sample_data/robot_text.txt\"\n",
        "# Defining lines as a list of each line\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "  lines = f.read().split('\\n')\n",
        "with open(data_path2, 'r', encoding='utf-8') as f:\n",
        "  lines2 = f.read().split('\\n')\n",
        "lines = [re.sub(r\"\\[\\w+\\]\",'hi',line) for line in lines]\n",
        "lines = [\" \".join(re.findall(r\"\\w+\",line)) for line in lines]\n",
        "lines2 = [re.sub(r\"\\[\\w+\\]\",'',line) for line in lines2]\n",
        "lines2 = [\" \".join(re.findall(r\"\\w+\",line)) for line in lines2]\n",
        "# Grouping lines by response pair\n",
        "pairs = list(zip(lines,lines2))\n",
        "#random.shuffle(pairs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw7iFyTEFriu"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "input_docs = []\n",
        "target_docs = []\n",
        "input_tokens = set()\n",
        "target_tokens = set()\n",
        "for line in pairs[:400]:\n",
        "  input_doc, target_doc = line[0], line[1]\n",
        "  # Appending each input sentence to input_docs\n",
        "  input_docs.append(input_doc)\n",
        "  # Splitting words from punctuation  \n",
        "  target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
        "  # Redefine target_doc below and append it to target_docs\n",
        "  target_doc = '<START> ' + target_doc + ' <END>'\n",
        "  target_docs.append(target_doc)\n",
        "  \n",
        "  # Now we split up each sentence into words and add each unique word to our vocabulary set\n",
        "  for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n",
        "    if token not in input_tokens:\n",
        "      input_tokens.add(token)\n",
        "  for token in target_doc.split():\n",
        "    if token not in target_tokens:\n",
        "      target_tokens.add(token)\n",
        "input_tokens = sorted(list(input_tokens))\n",
        "target_tokens = sorted(list(target_tokens))\n",
        "num_encoder_tokens = len(input_tokens)\n",
        "num_decoder_tokens = len(target_tokens)\n",
        "\n",
        "input_features_dict = dict(\n",
        "    [(token, i) for i, token in enumerate(input_tokens)])\n",
        "target_features_dict = dict(\n",
        "    [(token, i) for i, token in enumerate(target_tokens)])\n",
        "\n",
        "reverse_input_features_dict = dict(\n",
        "    (i, token) for token, i in input_features_dict.items())\n",
        "reverse_target_features_dict = dict(\n",
        "    (i, token) for token, i in target_features_dict.items())\n",
        "\n",
        "\n",
        "max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n",
        "max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "\n",
        "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
        "    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n",
        "        #Assign 1. for the current line, timestep, & word in encoder_input_data\n",
        "        encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n",
        "    \n",
        "    for timestep, token in enumerate(target_doc.split()):\n",
        "        decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n",
        "        if timestep > 0:\n",
        "            decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPRH_kUNKaHE",
        "outputId": "bd385f5d-2677-434f-d32a-f74400a8d5c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(pairs[:5])\n",
        "print(input_docs[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('hi', 'hi there how are you'), ('oh thanks i m fine this is an evening in my timezone', 'here is afternoon'), ('how do you feel today tell me something about yourself', 'my name is rdany but you can call me dany the r means robot i hope we can be virtual friends'), ('how many virtual friends have you got', 'i have many but not enough to fully understand humans beings'), ('is that forbidden for you to tell the exact number', 'i ve talked with 143 users counting 7294 lines of text')]\n",
            "['hi', 'oh thanks i m fine this is an evening in my timezone', 'how do you feel today tell me something about yourself', 'how many virtual friends have you got', 'is that forbidden for you to tell the exact number']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZZcikCkFulO",
        "outputId": "5f9b9075-2575-46f3-bbe7-04a58db49233",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "from keras.models import Model\n",
        "#Dimensionality\n",
        "dimensionality = 256\n",
        "#The batch size and number of epochs\n",
        "batch_size = 10\n",
        "epochs = 600\n",
        "#Encoder\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder_lstm = LSTM(dimensionality, return_state=True)\n",
        "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [state_hidden, state_cell]\n",
        "#Decoder\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(dimensionality, return_sequences=True, return_state=True)\n",
        "decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "#Model\n",
        "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "#Compiling\n",
        "training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n",
        "#Training\n",
        "training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split = 0.2)\n",
        "training_model.save('training_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "32/32 [==============================] - 11s 74ms/step - loss: 1.2405 - accuracy: 0.0226 - val_loss: 1.3531 - val_accuracy: 0.0200\n",
            "Epoch 2/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1814 - accuracy: 0.0238 - val_loss: 1.3714 - val_accuracy: 0.0200\n",
            "Epoch 3/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1823 - accuracy: 0.0239 - val_loss: 1.4289 - val_accuracy: 0.0210\n",
            "Epoch 4/600\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 1.1778 - accuracy: 0.0239 - val_loss: 1.4086 - val_accuracy: 0.0200\n",
            "Epoch 5/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1748 - accuracy: 0.0241 - val_loss: 1.4300 - val_accuracy: 0.0200\n",
            "Epoch 6/600\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 1.1758 - accuracy: 0.0241 - val_loss: 1.4460 - val_accuracy: 0.0200\n",
            "Epoch 7/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1720 - accuracy: 0.0240 - val_loss: 1.4630 - val_accuracy: 0.0200\n",
            "Epoch 8/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1709 - accuracy: 0.0240 - val_loss: 1.5134 - val_accuracy: 0.0210\n",
            "Epoch 9/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1728 - accuracy: 0.0241 - val_loss: 1.5014 - val_accuracy: 0.0200\n",
            "Epoch 10/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1691 - accuracy: 0.0241 - val_loss: 1.5092 - val_accuracy: 0.0200\n",
            "Epoch 11/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1697 - accuracy: 0.0243 - val_loss: 1.5320 - val_accuracy: 0.0200\n",
            "Epoch 12/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1684 - accuracy: 0.0239 - val_loss: 1.5470 - val_accuracy: 0.0200\n",
            "Epoch 13/600\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 1.1645 - accuracy: 0.0243 - val_loss: 1.5624 - val_accuracy: 0.0195\n",
            "Epoch 14/600\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 1.1626 - accuracy: 0.0244 - val_loss: 1.5772 - val_accuracy: 0.0200\n",
            "Epoch 15/600\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 1.1620 - accuracy: 0.0241 - val_loss: 1.5918 - val_accuracy: 0.0198\n",
            "Epoch 16/600\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 1.1606 - accuracy: 0.0246 - val_loss: 1.6033 - val_accuracy: 0.0198\n",
            "Epoch 17/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.1607 - accuracy: 0.0248 - val_loss: 1.6146 - val_accuracy: 0.0198\n",
            "Epoch 18/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1593 - accuracy: 0.0239 - val_loss: 1.6211 - val_accuracy: 0.0200\n",
            "Epoch 19/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.1567 - accuracy: 0.0247 - val_loss: 1.6341 - val_accuracy: 0.0200\n",
            "Epoch 20/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1564 - accuracy: 0.0247 - val_loss: 1.6434 - val_accuracy: 0.0200\n",
            "Epoch 21/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1544 - accuracy: 0.0256 - val_loss: 1.6475 - val_accuracy: 0.0200\n",
            "Epoch 22/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1552 - accuracy: 0.0250 - val_loss: 1.6514 - val_accuracy: 0.0200\n",
            "Epoch 23/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1539 - accuracy: 0.0249 - val_loss: 1.6528 - val_accuracy: 0.0198\n",
            "Epoch 24/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1523 - accuracy: 0.0254 - val_loss: 1.6596 - val_accuracy: 0.0200\n",
            "Epoch 25/600\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 1.1490 - accuracy: 0.0258 - val_loss: 1.6591 - val_accuracy: 0.0203\n",
            "Epoch 26/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.1495 - accuracy: 0.0255 - val_loss: 1.6600 - val_accuracy: 0.0198\n",
            "Epoch 27/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.1484 - accuracy: 0.0256 - val_loss: 1.6616 - val_accuracy: 0.0198\n",
            "Epoch 28/600\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 1.1476 - accuracy: 0.0255 - val_loss: 1.6619 - val_accuracy: 0.0205\n",
            "Epoch 29/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.1437 - accuracy: 0.0259 - val_loss: 1.6619 - val_accuracy: 0.0203\n",
            "Epoch 30/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 1.1435 - accuracy: 0.0262 - val_loss: 1.6667 - val_accuracy: 0.0200\n",
            "Epoch 31/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.1422 - accuracy: 0.0258 - val_loss: 1.6648 - val_accuracy: 0.0203\n",
            "Epoch 32/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1417 - accuracy: 0.0262 - val_loss: 1.6661 - val_accuracy: 0.0205\n",
            "Epoch 33/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1419 - accuracy: 0.0256 - val_loss: 1.6634 - val_accuracy: 0.0203\n",
            "Epoch 34/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.1400 - accuracy: 0.0256 - val_loss: 1.6702 - val_accuracy: 0.0192\n",
            "Epoch 35/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1386 - accuracy: 0.0262 - val_loss: 1.6655 - val_accuracy: 0.0203\n",
            "Epoch 36/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1392 - accuracy: 0.0265 - val_loss: 1.6691 - val_accuracy: 0.0200\n",
            "Epoch 37/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1359 - accuracy: 0.0266 - val_loss: 1.6671 - val_accuracy: 0.0203\n",
            "Epoch 38/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1364 - accuracy: 0.0266 - val_loss: 1.6644 - val_accuracy: 0.0213\n",
            "Epoch 39/600\n",
            "32/32 [==============================] - 1s 15ms/step - loss: 1.1555 - accuracy: 0.0250 - val_loss: 1.6320 - val_accuracy: 0.0190\n",
            "Epoch 40/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.2278 - accuracy: 0.0199 - val_loss: 1.5860 - val_accuracy: 0.0205\n",
            "Epoch 41/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.2082 - accuracy: 0.0214 - val_loss: 1.5860 - val_accuracy: 0.0192\n",
            "Epoch 42/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.2031 - accuracy: 0.0226 - val_loss: 1.6035 - val_accuracy: 0.0190\n",
            "Epoch 43/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.2046 - accuracy: 0.0227 - val_loss: 1.6193 - val_accuracy: 0.0192\n",
            "Epoch 44/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1944 - accuracy: 0.0228 - val_loss: 1.6137 - val_accuracy: 0.0200\n",
            "Epoch 45/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1794 - accuracy: 0.0234 - val_loss: 1.6213 - val_accuracy: 0.0198\n",
            "Epoch 46/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1796 - accuracy: 0.0234 - val_loss: 1.6205 - val_accuracy: 0.0207\n",
            "Epoch 47/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.1717 - accuracy: 0.0241 - val_loss: 1.6314 - val_accuracy: 0.0207\n",
            "Epoch 48/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1730 - accuracy: 0.0235 - val_loss: 1.6382 - val_accuracy: 0.0200\n",
            "Epoch 49/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 1.1643 - accuracy: 0.0246 - val_loss: 1.6472 - val_accuracy: 0.0198\n",
            "Epoch 50/600\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 1.1653 - accuracy: 0.0243 - val_loss: 1.6592 - val_accuracy: 0.0200\n",
            "Epoch 51/600\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 1.1634 - accuracy: 0.0243 - val_loss: 1.6531 - val_accuracy: 0.0200\n",
            "Epoch 52/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1636 - accuracy: 0.0246 - val_loss: 1.6553 - val_accuracy: 0.0198\n",
            "Epoch 53/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1605 - accuracy: 0.0246 - val_loss: 1.6570 - val_accuracy: 0.0215\n",
            "Epoch 54/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1562 - accuracy: 0.0250 - val_loss: 1.6731 - val_accuracy: 0.0198\n",
            "Epoch 55/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1514 - accuracy: 0.0254 - val_loss: 1.6769 - val_accuracy: 0.0207\n",
            "Epoch 56/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1459 - accuracy: 0.0256 - val_loss: 1.6750 - val_accuracy: 0.0203\n",
            "Epoch 57/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.1466 - accuracy: 0.0255 - val_loss: 1.6814 - val_accuracy: 0.0203\n",
            "Epoch 58/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1463 - accuracy: 0.0254 - val_loss: 1.6815 - val_accuracy: 0.0203\n",
            "Epoch 59/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1423 - accuracy: 0.0258 - val_loss: 1.6918 - val_accuracy: 0.0207\n",
            "Epoch 60/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1406 - accuracy: 0.0259 - val_loss: 1.6856 - val_accuracy: 0.0200\n",
            "Epoch 61/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1400 - accuracy: 0.0260 - val_loss: 1.6868 - val_accuracy: 0.0200\n",
            "Epoch 62/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1373 - accuracy: 0.0262 - val_loss: 1.6869 - val_accuracy: 0.0203\n",
            "Epoch 63/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1386 - accuracy: 0.0260 - val_loss: 1.6929 - val_accuracy: 0.0200\n",
            "Epoch 64/600\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 1.1390 - accuracy: 0.0260 - val_loss: 1.6856 - val_accuracy: 0.0200\n",
            "Epoch 65/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1343 - accuracy: 0.0260 - val_loss: 1.6904 - val_accuracy: 0.0205\n",
            "Epoch 66/600\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 1.1350 - accuracy: 0.0262 - val_loss: 1.6881 - val_accuracy: 0.0207\n",
            "Epoch 67/600\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 1.1322 - accuracy: 0.0263 - val_loss: 1.6951 - val_accuracy: 0.0203\n",
            "Epoch 68/600\n",
            "32/32 [==============================] - 1s 22ms/step - loss: 1.1321 - accuracy: 0.0261 - val_loss: 1.6900 - val_accuracy: 0.0207\n",
            "Epoch 69/600\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 1.1359 - accuracy: 0.0259 - val_loss: 1.6952 - val_accuracy: 0.0207\n",
            "Epoch 70/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.1334 - accuracy: 0.0264 - val_loss: 1.6924 - val_accuracy: 0.0200\n",
            "Epoch 71/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1305 - accuracy: 0.0263 - val_loss: 1.6922 - val_accuracy: 0.0200\n",
            "Epoch 72/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 1.1312 - accuracy: 0.0263 - val_loss: 1.6935 - val_accuracy: 0.0207\n",
            "Epoch 73/600\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 1.1310 - accuracy: 0.0262 - val_loss: 1.6904 - val_accuracy: 0.0207\n",
            "Epoch 74/600\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 1.1295 - accuracy: 0.0261 - val_loss: 1.6901 - val_accuracy: 0.0205\n",
            "Epoch 75/600\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 1.1276 - accuracy: 0.0265 - val_loss: 1.6923 - val_accuracy: 0.0195\n",
            "Epoch 76/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1293 - accuracy: 0.0265 - val_loss: 1.6946 - val_accuracy: 0.0200\n",
            "Epoch 77/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.1285 - accuracy: 0.0262 - val_loss: 1.6899 - val_accuracy: 0.0200\n",
            "Epoch 78/600\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 1.1263 - accuracy: 0.0264 - val_loss: 1.6959 - val_accuracy: 0.0205\n",
            "Epoch 79/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.1286 - accuracy: 0.0259 - val_loss: 1.6945 - val_accuracy: 0.0203\n",
            "Epoch 80/600\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 1.1260 - accuracy: 0.0263 - val_loss: 1.6900 - val_accuracy: 0.0198\n",
            "Epoch 81/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1273 - accuracy: 0.0262 - val_loss: 1.6865 - val_accuracy: 0.0203\n",
            "Epoch 82/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.1235 - accuracy: 0.0264 - val_loss: 1.6954 - val_accuracy: 0.0200\n",
            "Epoch 83/600\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 1.1229 - accuracy: 0.0268 - val_loss: 1.6894 - val_accuracy: 0.0203\n",
            "Epoch 84/600\n",
            "32/32 [==============================] - 1s 23ms/step - loss: 1.1239 - accuracy: 0.0267 - val_loss: 1.6931 - val_accuracy: 0.0198\n",
            "Epoch 85/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1256 - accuracy: 0.0262 - val_loss: 1.6908 - val_accuracy: 0.0200\n",
            "Epoch 86/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.1215 - accuracy: 0.0265 - val_loss: 1.6861 - val_accuracy: 0.0203\n",
            "Epoch 87/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1199 - accuracy: 0.0268 - val_loss: 1.6872 - val_accuracy: 0.0200\n",
            "Epoch 88/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1205 - accuracy: 0.0262 - val_loss: 1.6927 - val_accuracy: 0.0200\n",
            "Epoch 89/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1217 - accuracy: 0.0266 - val_loss: 1.6870 - val_accuracy: 0.0198\n",
            "Epoch 90/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1206 - accuracy: 0.0266 - val_loss: 1.6922 - val_accuracy: 0.0200\n",
            "Epoch 91/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1182 - accuracy: 0.0269 - val_loss: 1.6927 - val_accuracy: 0.0203\n",
            "Epoch 92/600\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 1.1175 - accuracy: 0.0266 - val_loss: 1.6958 - val_accuracy: 0.0195\n",
            "Epoch 93/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1182 - accuracy: 0.0268 - val_loss: 1.6915 - val_accuracy: 0.0190\n",
            "Epoch 94/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.1160 - accuracy: 0.0265 - val_loss: 1.6940 - val_accuracy: 0.0190\n",
            "Epoch 95/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1168 - accuracy: 0.0263 - val_loss: 1.7003 - val_accuracy: 0.0205\n",
            "Epoch 96/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.1131 - accuracy: 0.0270 - val_loss: 1.6973 - val_accuracy: 0.0205\n",
            "Epoch 97/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 1.1118 - accuracy: 0.0275 - val_loss: 1.6950 - val_accuracy: 0.0200\n",
            "Epoch 98/600\n",
            "32/32 [==============================] - 1s 23ms/step - loss: 1.1111 - accuracy: 0.0262 - val_loss: 1.6999 - val_accuracy: 0.0200\n",
            "Epoch 99/600\n",
            "32/32 [==============================] - 1s 23ms/step - loss: 1.1124 - accuracy: 0.0270 - val_loss: 1.6918 - val_accuracy: 0.0205\n",
            "Epoch 100/600\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 1.1138 - accuracy: 0.0266 - val_loss: 1.6930 - val_accuracy: 0.0210\n",
            "Epoch 101/600\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 1.1109 - accuracy: 0.0272 - val_loss: 1.6978 - val_accuracy: 0.0200\n",
            "Epoch 102/600\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 1.1144 - accuracy: 0.0269 - val_loss: 1.6960 - val_accuracy: 0.0207\n",
            "Epoch 103/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.1164 - accuracy: 0.0268 - val_loss: 1.6925 - val_accuracy: 0.0198\n",
            "Epoch 104/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.1149 - accuracy: 0.0265 - val_loss: 1.6897 - val_accuracy: 0.0207\n",
            "Epoch 105/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1135 - accuracy: 0.0264 - val_loss: 1.6994 - val_accuracy: 0.0205\n",
            "Epoch 106/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1116 - accuracy: 0.0269 - val_loss: 1.6972 - val_accuracy: 0.0205\n",
            "Epoch 107/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.1114 - accuracy: 0.0268 - val_loss: 1.6969 - val_accuracy: 0.0205\n",
            "Epoch 108/600\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 1.1065 - accuracy: 0.0277 - val_loss: 1.6925 - val_accuracy: 0.0203\n",
            "Epoch 109/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1070 - accuracy: 0.0272 - val_loss: 1.6963 - val_accuracy: 0.0195\n",
            "Epoch 110/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1183 - accuracy: 0.0259 - val_loss: 1.6956 - val_accuracy: 0.0195\n",
            "Epoch 111/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1086 - accuracy: 0.0273 - val_loss: 1.7035 - val_accuracy: 0.0200\n",
            "Epoch 112/600\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 1.1063 - accuracy: 0.0272 - val_loss: 1.6993 - val_accuracy: 0.0198\n",
            "Epoch 113/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1071 - accuracy: 0.0268 - val_loss: 1.6939 - val_accuracy: 0.0195\n",
            "Epoch 114/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1049 - accuracy: 0.0269 - val_loss: 1.6993 - val_accuracy: 0.0203\n",
            "Epoch 115/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1082 - accuracy: 0.0270 - val_loss: 1.6872 - val_accuracy: 0.0198\n",
            "Epoch 116/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 1.1027 - accuracy: 0.0280 - val_loss: 1.6943 - val_accuracy: 0.0192\n",
            "Epoch 117/600\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 1.1032 - accuracy: 0.0276 - val_loss: 1.6910 - val_accuracy: 0.0205\n",
            "Epoch 118/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.1034 - accuracy: 0.0277 - val_loss: 1.7034 - val_accuracy: 0.0200\n",
            "Epoch 119/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.1018 - accuracy: 0.0282 - val_loss: 1.6874 - val_accuracy: 0.0192\n",
            "Epoch 120/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1013 - accuracy: 0.0278 - val_loss: 1.7019 - val_accuracy: 0.0198\n",
            "Epoch 121/600\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 1.0987 - accuracy: 0.0286 - val_loss: 1.6945 - val_accuracy: 0.0200\n",
            "Epoch 122/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1000 - accuracy: 0.0281 - val_loss: 1.6970 - val_accuracy: 0.0207\n",
            "Epoch 123/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0959 - accuracy: 0.0288 - val_loss: 1.7032 - val_accuracy: 0.0207\n",
            "Epoch 124/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0991 - accuracy: 0.0285 - val_loss: 1.6965 - val_accuracy: 0.0207\n",
            "Epoch 125/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0980 - accuracy: 0.0288 - val_loss: 1.7067 - val_accuracy: 0.0205\n",
            "Epoch 126/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0969 - accuracy: 0.0286 - val_loss: 1.6959 - val_accuracy: 0.0203\n",
            "Epoch 127/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0972 - accuracy: 0.0281 - val_loss: 1.7026 - val_accuracy: 0.0207\n",
            "Epoch 128/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0955 - accuracy: 0.0290 - val_loss: 1.7040 - val_accuracy: 0.0215\n",
            "Epoch 129/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0942 - accuracy: 0.0294 - val_loss: 1.6961 - val_accuracy: 0.0192\n",
            "Epoch 130/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0939 - accuracy: 0.0292 - val_loss: 1.7031 - val_accuracy: 0.0198\n",
            "Epoch 131/600\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 1.0938 - accuracy: 0.0291 - val_loss: 1.7054 - val_accuracy: 0.0207\n",
            "Epoch 132/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1016 - accuracy: 0.0292 - val_loss: 1.6951 - val_accuracy: 0.0203\n",
            "Epoch 133/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0928 - accuracy: 0.0299 - val_loss: 1.7043 - val_accuracy: 0.0195\n",
            "Epoch 134/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1007 - accuracy: 0.0284 - val_loss: 1.7018 - val_accuracy: 0.0192\n",
            "Epoch 135/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0938 - accuracy: 0.0298 - val_loss: 1.6960 - val_accuracy: 0.0192\n",
            "Epoch 136/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0964 - accuracy: 0.0298 - val_loss: 1.7076 - val_accuracy: 0.0205\n",
            "Epoch 137/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0911 - accuracy: 0.0301 - val_loss: 1.7047 - val_accuracy: 0.0195\n",
            "Epoch 138/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0945 - accuracy: 0.0293 - val_loss: 1.6964 - val_accuracy: 0.0200\n",
            "Epoch 139/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0889 - accuracy: 0.0302 - val_loss: 1.6982 - val_accuracy: 0.0198\n",
            "Epoch 140/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0885 - accuracy: 0.0302 - val_loss: 1.7197 - val_accuracy: 0.0205\n",
            "Epoch 141/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0877 - accuracy: 0.0304 - val_loss: 1.7046 - val_accuracy: 0.0188\n",
            "Epoch 142/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0884 - accuracy: 0.0304 - val_loss: 1.7181 - val_accuracy: 0.0215\n",
            "Epoch 143/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.1032 - accuracy: 0.0292 - val_loss: 1.6990 - val_accuracy: 0.0213\n",
            "Epoch 144/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0896 - accuracy: 0.0300 - val_loss: 1.7069 - val_accuracy: 0.0210\n",
            "Epoch 145/600\n",
            "32/32 [==============================] - 1s 23ms/step - loss: 1.0895 - accuracy: 0.0290 - val_loss: 1.7081 - val_accuracy: 0.0198\n",
            "Epoch 146/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 1.0895 - accuracy: 0.0299 - val_loss: 1.7018 - val_accuracy: 0.0195\n",
            "Epoch 147/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 1.0894 - accuracy: 0.0304 - val_loss: 1.7003 - val_accuracy: 0.0195\n",
            "Epoch 148/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0879 - accuracy: 0.0304 - val_loss: 1.7092 - val_accuracy: 0.0205\n",
            "Epoch 149/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0865 - accuracy: 0.0310 - val_loss: 1.7021 - val_accuracy: 0.0195\n",
            "Epoch 150/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0858 - accuracy: 0.0308 - val_loss: 1.7099 - val_accuracy: 0.0192\n",
            "Epoch 151/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0866 - accuracy: 0.0310 - val_loss: 1.7031 - val_accuracy: 0.0203\n",
            "Epoch 152/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0774 - accuracy: 0.0318 - val_loss: 1.7106 - val_accuracy: 0.0210\n",
            "Epoch 153/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0819 - accuracy: 0.0312 - val_loss: 1.6986 - val_accuracy: 0.0190\n",
            "Epoch 154/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0806 - accuracy: 0.0311 - val_loss: 1.7040 - val_accuracy: 0.0200\n",
            "Epoch 155/600\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 1.0824 - accuracy: 0.0306 - val_loss: 1.7063 - val_accuracy: 0.0198\n",
            "Epoch 156/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0803 - accuracy: 0.0315 - val_loss: 1.7132 - val_accuracy: 0.0190\n",
            "Epoch 157/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0835 - accuracy: 0.0310 - val_loss: 1.7040 - val_accuracy: 0.0205\n",
            "Epoch 158/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0779 - accuracy: 0.0316 - val_loss: 1.6968 - val_accuracy: 0.0198\n",
            "Epoch 159/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0769 - accuracy: 0.0314 - val_loss: 1.7094 - val_accuracy: 0.0195\n",
            "Epoch 160/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0768 - accuracy: 0.0314 - val_loss: 1.7022 - val_accuracy: 0.0200\n",
            "Epoch 161/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0789 - accuracy: 0.0308 - val_loss: 1.7109 - val_accuracy: 0.0195\n",
            "Epoch 162/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0768 - accuracy: 0.0315 - val_loss: 1.7071 - val_accuracy: 0.0200\n",
            "Epoch 163/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0792 - accuracy: 0.0320 - val_loss: 1.7007 - val_accuracy: 0.0192\n",
            "Epoch 164/600\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 1.0736 - accuracy: 0.0316 - val_loss: 1.7046 - val_accuracy: 0.0203\n",
            "Epoch 165/600\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 1.0730 - accuracy: 0.0317 - val_loss: 1.6987 - val_accuracy: 0.0203\n",
            "Epoch 166/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0705 - accuracy: 0.0326 - val_loss: 1.7070 - val_accuracy: 0.0198\n",
            "Epoch 167/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0742 - accuracy: 0.0318 - val_loss: 1.7069 - val_accuracy: 0.0207\n",
            "Epoch 168/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0708 - accuracy: 0.0317 - val_loss: 1.7076 - val_accuracy: 0.0192\n",
            "Epoch 169/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0710 - accuracy: 0.0319 - val_loss: 1.6995 - val_accuracy: 0.0205\n",
            "Epoch 170/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 1.0680 - accuracy: 0.0325 - val_loss: 1.7054 - val_accuracy: 0.0192\n",
            "Epoch 171/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0690 - accuracy: 0.0328 - val_loss: 1.7051 - val_accuracy: 0.0198\n",
            "Epoch 172/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 1.0675 - accuracy: 0.0317 - val_loss: 1.7073 - val_accuracy: 0.0192\n",
            "Epoch 173/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0688 - accuracy: 0.0319 - val_loss: 1.7088 - val_accuracy: 0.0192\n",
            "Epoch 174/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 1.0681 - accuracy: 0.0324 - val_loss: 1.7133 - val_accuracy: 0.0192\n",
            "Epoch 175/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0682 - accuracy: 0.0319 - val_loss: 1.7127 - val_accuracy: 0.0198\n",
            "Epoch 176/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 1.0661 - accuracy: 0.0324 - val_loss: 1.7066 - val_accuracy: 0.0195\n",
            "Epoch 177/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0680 - accuracy: 0.0326 - val_loss: 1.7137 - val_accuracy: 0.0192\n",
            "Epoch 178/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0657 - accuracy: 0.0327 - val_loss: 1.7061 - val_accuracy: 0.0192\n",
            "Epoch 179/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0651 - accuracy: 0.0316 - val_loss: 1.7027 - val_accuracy: 0.0200\n",
            "Epoch 180/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0628 - accuracy: 0.0322 - val_loss: 1.7031 - val_accuracy: 0.0190\n",
            "Epoch 181/600\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 1.0616 - accuracy: 0.0330 - val_loss: 1.7118 - val_accuracy: 0.0195\n",
            "Epoch 182/600\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 1.0606 - accuracy: 0.0327 - val_loss: 1.7030 - val_accuracy: 0.0198\n",
            "Epoch 183/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0607 - accuracy: 0.0332 - val_loss: 1.7139 - val_accuracy: 0.0200\n",
            "Epoch 184/600\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 1.0635 - accuracy: 0.0326 - val_loss: 1.7165 - val_accuracy: 0.0203\n",
            "Epoch 185/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0593 - accuracy: 0.0327 - val_loss: 1.7023 - val_accuracy: 0.0200\n",
            "Epoch 186/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0591 - accuracy: 0.0333 - val_loss: 1.7106 - val_accuracy: 0.0198\n",
            "Epoch 187/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0583 - accuracy: 0.0327 - val_loss: 1.7087 - val_accuracy: 0.0195\n",
            "Epoch 188/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0579 - accuracy: 0.0326 - val_loss: 1.7093 - val_accuracy: 0.0190\n",
            "Epoch 189/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0557 - accuracy: 0.0334 - val_loss: 1.7027 - val_accuracy: 0.0195\n",
            "Epoch 190/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0547 - accuracy: 0.0336 - val_loss: 1.7179 - val_accuracy: 0.0198\n",
            "Epoch 191/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0614 - accuracy: 0.0331 - val_loss: 1.7118 - val_accuracy: 0.0190\n",
            "Epoch 192/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0546 - accuracy: 0.0338 - val_loss: 1.7031 - val_accuracy: 0.0195\n",
            "Epoch 193/600\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 1.0488 - accuracy: 0.0343 - val_loss: 1.7106 - val_accuracy: 0.0198\n",
            "Epoch 194/600\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 1.0525 - accuracy: 0.0336 - val_loss: 1.7108 - val_accuracy: 0.0195\n",
            "Epoch 195/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0515 - accuracy: 0.0336 - val_loss: 1.7119 - val_accuracy: 0.0188\n",
            "Epoch 196/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0528 - accuracy: 0.0336 - val_loss: 1.7191 - val_accuracy: 0.0198\n",
            "Epoch 197/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0514 - accuracy: 0.0341 - val_loss: 1.7121 - val_accuracy: 0.0198\n",
            "Epoch 198/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0487 - accuracy: 0.0341 - val_loss: 1.7046 - val_accuracy: 0.0198\n",
            "Epoch 199/600\n",
            "32/32 [==============================] - 1s 22ms/step - loss: 1.0515 - accuracy: 0.0338 - val_loss: 1.7108 - val_accuracy: 0.0198\n",
            "Epoch 200/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0495 - accuracy: 0.0339 - val_loss: 1.7008 - val_accuracy: 0.0195\n",
            "Epoch 201/600\n",
            "32/32 [==============================] - 1s 22ms/step - loss: 1.0493 - accuracy: 0.0343 - val_loss: 1.6972 - val_accuracy: 0.0205\n",
            "Epoch 202/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0498 - accuracy: 0.0338 - val_loss: 1.7032 - val_accuracy: 0.0198\n",
            "Epoch 203/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0442 - accuracy: 0.0342 - val_loss: 1.7065 - val_accuracy: 0.0203\n",
            "Epoch 204/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0442 - accuracy: 0.0342 - val_loss: 1.7062 - val_accuracy: 0.0198\n",
            "Epoch 205/600\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 1.0478 - accuracy: 0.0339 - val_loss: 1.7187 - val_accuracy: 0.0200\n",
            "Epoch 206/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0465 - accuracy: 0.0342 - val_loss: 1.7148 - val_accuracy: 0.0203\n",
            "Epoch 207/600\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 1.0432 - accuracy: 0.0346 - val_loss: 1.7133 - val_accuracy: 0.0198\n",
            "Epoch 208/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0460 - accuracy: 0.0341 - val_loss: 1.7064 - val_accuracy: 0.0198\n",
            "Epoch 209/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0403 - accuracy: 0.0348 - val_loss: 1.7062 - val_accuracy: 0.0200\n",
            "Epoch 210/600\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 1.0399 - accuracy: 0.0353 - val_loss: 1.7089 - val_accuracy: 0.0210\n",
            "Epoch 211/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0437 - accuracy: 0.0341 - val_loss: 1.7153 - val_accuracy: 0.0200\n",
            "Epoch 212/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0413 - accuracy: 0.0352 - val_loss: 1.7096 - val_accuracy: 0.0215\n",
            "Epoch 213/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0439 - accuracy: 0.0350 - val_loss: 1.7090 - val_accuracy: 0.0207\n",
            "Epoch 214/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0418 - accuracy: 0.0351 - val_loss: 1.7207 - val_accuracy: 0.0205\n",
            "Epoch 215/600\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 1.0398 - accuracy: 0.0357 - val_loss: 1.7156 - val_accuracy: 0.0200\n",
            "Epoch 216/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0384 - accuracy: 0.0356 - val_loss: 1.7127 - val_accuracy: 0.0198\n",
            "Epoch 217/600\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 1.0390 - accuracy: 0.0356 - val_loss: 1.7163 - val_accuracy: 0.0205\n",
            "Epoch 218/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 1.0376 - accuracy: 0.0350 - val_loss: 1.7241 - val_accuracy: 0.0198\n",
            "Epoch 219/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0404 - accuracy: 0.0354 - val_loss: 1.7200 - val_accuracy: 0.0207\n",
            "Epoch 220/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0431 - accuracy: 0.0355 - val_loss: 1.7106 - val_accuracy: 0.0195\n",
            "Epoch 221/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0300 - accuracy: 0.0362 - val_loss: 1.7235 - val_accuracy: 0.0195\n",
            "Epoch 222/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0313 - accuracy: 0.0356 - val_loss: 1.7153 - val_accuracy: 0.0200\n",
            "Epoch 223/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0324 - accuracy: 0.0356 - val_loss: 1.7162 - val_accuracy: 0.0192\n",
            "Epoch 224/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0352 - accuracy: 0.0358 - val_loss: 1.7182 - val_accuracy: 0.0198\n",
            "Epoch 225/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0309 - accuracy: 0.0363 - val_loss: 1.7126 - val_accuracy: 0.0200\n",
            "Epoch 226/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0297 - accuracy: 0.0359 - val_loss: 1.7110 - val_accuracy: 0.0203\n",
            "Epoch 227/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0306 - accuracy: 0.0361 - val_loss: 1.7126 - val_accuracy: 0.0207\n",
            "Epoch 228/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0267 - accuracy: 0.0369 - val_loss: 1.7086 - val_accuracy: 0.0190\n",
            "Epoch 229/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 1.0285 - accuracy: 0.0356 - val_loss: 1.7245 - val_accuracy: 0.0203\n",
            "Epoch 230/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 1.0250 - accuracy: 0.0369 - val_loss: 1.7158 - val_accuracy: 0.0195\n",
            "Epoch 231/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0301 - accuracy: 0.0362 - val_loss: 1.7144 - val_accuracy: 0.0192\n",
            "Epoch 232/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0231 - accuracy: 0.0373 - val_loss: 1.7173 - val_accuracy: 0.0195\n",
            "Epoch 233/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0235 - accuracy: 0.0375 - val_loss: 1.7251 - val_accuracy: 0.0203\n",
            "Epoch 234/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0254 - accuracy: 0.0378 - val_loss: 1.7194 - val_accuracy: 0.0200\n",
            "Epoch 235/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0204 - accuracy: 0.0376 - val_loss: 1.7041 - val_accuracy: 0.0207\n",
            "Epoch 236/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0216 - accuracy: 0.0379 - val_loss: 1.7194 - val_accuracy: 0.0192\n",
            "Epoch 237/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0200 - accuracy: 0.0385 - val_loss: 1.7186 - val_accuracy: 0.0200\n",
            "Epoch 238/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0204 - accuracy: 0.0374 - val_loss: 1.7171 - val_accuracy: 0.0205\n",
            "Epoch 239/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0182 - accuracy: 0.0379 - val_loss: 1.7161 - val_accuracy: 0.0198\n",
            "Epoch 240/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0174 - accuracy: 0.0372 - val_loss: 1.7133 - val_accuracy: 0.0205\n",
            "Epoch 241/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0144 - accuracy: 0.0395 - val_loss: 1.7187 - val_accuracy: 0.0203\n",
            "Epoch 242/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0127 - accuracy: 0.0387 - val_loss: 1.7233 - val_accuracy: 0.0195\n",
            "Epoch 243/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0215 - accuracy: 0.0373 - val_loss: 1.7271 - val_accuracy: 0.0203\n",
            "Epoch 244/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0119 - accuracy: 0.0393 - val_loss: 1.7176 - val_accuracy: 0.0200\n",
            "Epoch 245/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0130 - accuracy: 0.0386 - val_loss: 1.7370 - val_accuracy: 0.0200\n",
            "Epoch 246/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0111 - accuracy: 0.0397 - val_loss: 1.7156 - val_accuracy: 0.0198\n",
            "Epoch 247/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0114 - accuracy: 0.0391 - val_loss: 1.7236 - val_accuracy: 0.0195\n",
            "Epoch 248/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0107 - accuracy: 0.0397 - val_loss: 1.7145 - val_accuracy: 0.0200\n",
            "Epoch 249/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0158 - accuracy: 0.0385 - val_loss: 1.7284 - val_accuracy: 0.0192\n",
            "Epoch 250/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0112 - accuracy: 0.0400 - val_loss: 1.7233 - val_accuracy: 0.0198\n",
            "Epoch 251/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0095 - accuracy: 0.0394 - val_loss: 1.7119 - val_accuracy: 0.0203\n",
            "Epoch 252/600\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 1.0124 - accuracy: 0.0397 - val_loss: 1.7167 - val_accuracy: 0.0198\n",
            "Epoch 253/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0019 - accuracy: 0.0428 - val_loss: 1.7109 - val_accuracy: 0.0205\n",
            "Epoch 254/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0058 - accuracy: 0.0403 - val_loss: 1.7224 - val_accuracy: 0.0200\n",
            "Epoch 255/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0080 - accuracy: 0.0403 - val_loss: 1.7188 - val_accuracy: 0.0195\n",
            "Epoch 256/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0012 - accuracy: 0.0417 - val_loss: 1.7061 - val_accuracy: 0.0200\n",
            "Epoch 257/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0038 - accuracy: 0.0407 - val_loss: 1.7176 - val_accuracy: 0.0200\n",
            "Epoch 258/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0019 - accuracy: 0.0414 - val_loss: 1.7265 - val_accuracy: 0.0192\n",
            "Epoch 259/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0507 - accuracy: 0.0367 - val_loss: 1.7074 - val_accuracy: 0.0200\n",
            "Epoch 260/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0113 - accuracy: 0.0413 - val_loss: 1.7145 - val_accuracy: 0.0198\n",
            "Epoch 261/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.9946 - accuracy: 0.0435 - val_loss: 1.7210 - val_accuracy: 0.0203\n",
            "Epoch 262/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9936 - accuracy: 0.0430 - val_loss: 1.7116 - val_accuracy: 0.0195\n",
            "Epoch 263/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9955 - accuracy: 0.0428 - val_loss: 1.7138 - val_accuracy: 0.0188\n",
            "Epoch 264/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9963 - accuracy: 0.0417 - val_loss: 1.7122 - val_accuracy: 0.0190\n",
            "Epoch 265/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9972 - accuracy: 0.0419 - val_loss: 1.7058 - val_accuracy: 0.0207\n",
            "Epoch 266/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9982 - accuracy: 0.0419 - val_loss: 1.7192 - val_accuracy: 0.0195\n",
            "Epoch 267/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9917 - accuracy: 0.0426 - val_loss: 1.7151 - val_accuracy: 0.0203\n",
            "Epoch 268/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9968 - accuracy: 0.0423 - val_loss: 1.7145 - val_accuracy: 0.0205\n",
            "Epoch 269/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.9878 - accuracy: 0.0442 - val_loss: 1.7170 - val_accuracy: 0.0195\n",
            "Epoch 270/600\n",
            "32/32 [==============================] - 1s 22ms/step - loss: 0.9944 - accuracy: 0.0429 - val_loss: 1.7214 - val_accuracy: 0.0200\n",
            "Epoch 271/600\n",
            "32/32 [==============================] - 1s 24ms/step - loss: 0.9862 - accuracy: 0.0445 - val_loss: 1.7119 - val_accuracy: 0.0200\n",
            "Epoch 272/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9856 - accuracy: 0.0444 - val_loss: 1.7241 - val_accuracy: 0.0200\n",
            "Epoch 273/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9868 - accuracy: 0.0439 - val_loss: 1.7171 - val_accuracy: 0.0200\n",
            "Epoch 274/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9895 - accuracy: 0.0429 - val_loss: 1.7216 - val_accuracy: 0.0195\n",
            "Epoch 275/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9823 - accuracy: 0.0437 - val_loss: 1.7239 - val_accuracy: 0.0195\n",
            "Epoch 276/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9866 - accuracy: 0.0424 - val_loss: 1.7167 - val_accuracy: 0.0198\n",
            "Epoch 277/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9818 - accuracy: 0.0452 - val_loss: 1.7126 - val_accuracy: 0.0210\n",
            "Epoch 278/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9846 - accuracy: 0.0443 - val_loss: 1.7176 - val_accuracy: 0.0207\n",
            "Epoch 279/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9822 - accuracy: 0.0442 - val_loss: 1.7226 - val_accuracy: 0.0200\n",
            "Epoch 280/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9830 - accuracy: 0.0448 - val_loss: 1.7247 - val_accuracy: 0.0203\n",
            "Epoch 281/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.9785 - accuracy: 0.0454 - val_loss: 1.7214 - val_accuracy: 0.0198\n",
            "Epoch 282/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9854 - accuracy: 0.0436 - val_loss: 1.7139 - val_accuracy: 0.0210\n",
            "Epoch 283/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9715 - accuracy: 0.0461 - val_loss: 1.7152 - val_accuracy: 0.0205\n",
            "Epoch 284/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9731 - accuracy: 0.0460 - val_loss: 1.7119 - val_accuracy: 0.0210\n",
            "Epoch 285/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9731 - accuracy: 0.0459 - val_loss: 1.7181 - val_accuracy: 0.0200\n",
            "Epoch 286/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9734 - accuracy: 0.0462 - val_loss: 1.7141 - val_accuracy: 0.0207\n",
            "Epoch 287/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.9732 - accuracy: 0.0448 - val_loss: 1.7263 - val_accuracy: 0.0192\n",
            "Epoch 288/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9750 - accuracy: 0.0454 - val_loss: 1.7154 - val_accuracy: 0.0205\n",
            "Epoch 289/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9765 - accuracy: 0.0459 - val_loss: 1.7241 - val_accuracy: 0.0200\n",
            "Epoch 290/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9646 - accuracy: 0.0476 - val_loss: 1.7218 - val_accuracy: 0.0205\n",
            "Epoch 291/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9642 - accuracy: 0.0482 - val_loss: 1.7257 - val_accuracy: 0.0207\n",
            "Epoch 292/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9681 - accuracy: 0.0458 - val_loss: 1.7198 - val_accuracy: 0.0203\n",
            "Epoch 293/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9684 - accuracy: 0.0459 - val_loss: 1.7288 - val_accuracy: 0.0198\n",
            "Epoch 294/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9647 - accuracy: 0.0479 - val_loss: 1.7170 - val_accuracy: 0.0185\n",
            "Epoch 295/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9675 - accuracy: 0.0476 - val_loss: 1.7218 - val_accuracy: 0.0203\n",
            "Epoch 296/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9637 - accuracy: 0.0478 - val_loss: 1.7292 - val_accuracy: 0.0200\n",
            "Epoch 297/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9640 - accuracy: 0.0477 - val_loss: 1.7156 - val_accuracy: 0.0207\n",
            "Epoch 298/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.9603 - accuracy: 0.0482 - val_loss: 1.7204 - val_accuracy: 0.0200\n",
            "Epoch 299/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9629 - accuracy: 0.0474 - val_loss: 1.7226 - val_accuracy: 0.0203\n",
            "Epoch 300/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9590 - accuracy: 0.0484 - val_loss: 1.7272 - val_accuracy: 0.0198\n",
            "Epoch 301/600\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 0.9589 - accuracy: 0.0478 - val_loss: 1.7241 - val_accuracy: 0.0207\n",
            "Epoch 302/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9601 - accuracy: 0.0472 - val_loss: 1.7220 - val_accuracy: 0.0200\n",
            "Epoch 303/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9555 - accuracy: 0.0483 - val_loss: 1.7325 - val_accuracy: 0.0192\n",
            "Epoch 304/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9555 - accuracy: 0.0477 - val_loss: 1.7320 - val_accuracy: 0.0207\n",
            "Epoch 305/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9562 - accuracy: 0.0487 - val_loss: 1.7287 - val_accuracy: 0.0203\n",
            "Epoch 306/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9537 - accuracy: 0.0494 - val_loss: 1.7231 - val_accuracy: 0.0195\n",
            "Epoch 307/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9485 - accuracy: 0.0500 - val_loss: 1.7273 - val_accuracy: 0.0195\n",
            "Epoch 308/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9553 - accuracy: 0.0488 - val_loss: 1.7266 - val_accuracy: 0.0200\n",
            "Epoch 309/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9477 - accuracy: 0.0494 - val_loss: 1.7238 - val_accuracy: 0.0205\n",
            "Epoch 310/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9497 - accuracy: 0.0492 - val_loss: 1.7319 - val_accuracy: 0.0198\n",
            "Epoch 311/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9524 - accuracy: 0.0500 - val_loss: 1.7241 - val_accuracy: 0.0195\n",
            "Epoch 312/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9477 - accuracy: 0.0497 - val_loss: 1.7257 - val_accuracy: 0.0198\n",
            "Epoch 313/600\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.9428 - accuracy: 0.0508 - val_loss: 1.7247 - val_accuracy: 0.0205\n",
            "Epoch 314/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9500 - accuracy: 0.0490 - val_loss: 1.7258 - val_accuracy: 0.0205\n",
            "Epoch 315/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9417 - accuracy: 0.0508 - val_loss: 1.7303 - val_accuracy: 0.0205\n",
            "Epoch 316/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9436 - accuracy: 0.0508 - val_loss: 1.7280 - val_accuracy: 0.0195\n",
            "Epoch 317/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9427 - accuracy: 0.0512 - val_loss: 1.7344 - val_accuracy: 0.0190\n",
            "Epoch 318/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9416 - accuracy: 0.0511 - val_loss: 1.7302 - val_accuracy: 0.0205\n",
            "Epoch 319/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9342 - accuracy: 0.0525 - val_loss: 1.7270 - val_accuracy: 0.0192\n",
            "Epoch 320/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9358 - accuracy: 0.0518 - val_loss: 1.7281 - val_accuracy: 0.0195\n",
            "Epoch 321/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9439 - accuracy: 0.0496 - val_loss: 1.7300 - val_accuracy: 0.0200\n",
            "Epoch 322/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9343 - accuracy: 0.0522 - val_loss: 1.7285 - val_accuracy: 0.0190\n",
            "Epoch 323/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.9348 - accuracy: 0.0520 - val_loss: 1.7202 - val_accuracy: 0.0203\n",
            "Epoch 324/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9338 - accuracy: 0.0532 - val_loss: 1.7291 - val_accuracy: 0.0200\n",
            "Epoch 325/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.9349 - accuracy: 0.0521 - val_loss: 1.7243 - val_accuracy: 0.0198\n",
            "Epoch 326/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.9288 - accuracy: 0.0535 - val_loss: 1.7421 - val_accuracy: 0.0207\n",
            "Epoch 327/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9311 - accuracy: 0.0527 - val_loss: 1.7295 - val_accuracy: 0.0203\n",
            "Epoch 328/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9263 - accuracy: 0.0531 - val_loss: 1.7259 - val_accuracy: 0.0198\n",
            "Epoch 329/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9295 - accuracy: 0.0524 - val_loss: 1.7240 - val_accuracy: 0.0198\n",
            "Epoch 330/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9222 - accuracy: 0.0529 - val_loss: 1.7388 - val_accuracy: 0.0185\n",
            "Epoch 331/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9253 - accuracy: 0.0527 - val_loss: 1.7335 - val_accuracy: 0.0203\n",
            "Epoch 332/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9241 - accuracy: 0.0536 - val_loss: 1.7307 - val_accuracy: 0.0205\n",
            "Epoch 333/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9209 - accuracy: 0.0542 - val_loss: 1.7211 - val_accuracy: 0.0205\n",
            "Epoch 334/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9183 - accuracy: 0.0542 - val_loss: 1.7319 - val_accuracy: 0.0190\n",
            "Epoch 335/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9214 - accuracy: 0.0551 - val_loss: 1.7186 - val_accuracy: 0.0210\n",
            "Epoch 336/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9162 - accuracy: 0.0559 - val_loss: 1.7242 - val_accuracy: 0.0205\n",
            "Epoch 337/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9089 - accuracy: 0.0567 - val_loss: 1.7246 - val_accuracy: 0.0207\n",
            "Epoch 338/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9122 - accuracy: 0.0557 - val_loss: 1.7250 - val_accuracy: 0.0205\n",
            "Epoch 339/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9155 - accuracy: 0.0547 - val_loss: 1.7283 - val_accuracy: 0.0213\n",
            "Epoch 340/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9118 - accuracy: 0.0558 - val_loss: 1.7262 - val_accuracy: 0.0207\n",
            "Epoch 341/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9183 - accuracy: 0.0548 - val_loss: 1.7324 - val_accuracy: 0.0213\n",
            "Epoch 342/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9075 - accuracy: 0.0563 - val_loss: 1.7409 - val_accuracy: 0.0207\n",
            "Epoch 343/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9124 - accuracy: 0.0549 - val_loss: 1.7296 - val_accuracy: 0.0203\n",
            "Epoch 344/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9076 - accuracy: 0.0563 - val_loss: 1.7381 - val_accuracy: 0.0200\n",
            "Epoch 345/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9097 - accuracy: 0.0554 - val_loss: 1.7434 - val_accuracy: 0.0200\n",
            "Epoch 346/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9075 - accuracy: 0.0562 - val_loss: 1.7303 - val_accuracy: 0.0207\n",
            "Epoch 347/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9029 - accuracy: 0.0564 - val_loss: 1.7282 - val_accuracy: 0.0195\n",
            "Epoch 348/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9040 - accuracy: 0.0560 - val_loss: 1.7278 - val_accuracy: 0.0200\n",
            "Epoch 349/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9031 - accuracy: 0.0561 - val_loss: 1.7342 - val_accuracy: 0.0205\n",
            "Epoch 350/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9039 - accuracy: 0.0561 - val_loss: 1.7313 - val_accuracy: 0.0195\n",
            "Epoch 351/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9022 - accuracy: 0.0573 - val_loss: 1.7371 - val_accuracy: 0.0210\n",
            "Epoch 352/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8977 - accuracy: 0.0580 - val_loss: 1.7357 - val_accuracy: 0.0210\n",
            "Epoch 353/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8977 - accuracy: 0.0575 - val_loss: 1.7342 - val_accuracy: 0.0200\n",
            "Epoch 354/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8969 - accuracy: 0.0582 - val_loss: 1.7385 - val_accuracy: 0.0200\n",
            "Epoch 355/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8964 - accuracy: 0.0572 - val_loss: 1.7297 - val_accuracy: 0.0210\n",
            "Epoch 356/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8954 - accuracy: 0.0584 - val_loss: 1.7229 - val_accuracy: 0.0203\n",
            "Epoch 357/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8918 - accuracy: 0.0584 - val_loss: 1.7398 - val_accuracy: 0.0192\n",
            "Epoch 358/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8917 - accuracy: 0.0582 - val_loss: 1.7369 - val_accuracy: 0.0205\n",
            "Epoch 359/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8887 - accuracy: 0.0596 - val_loss: 1.7331 - val_accuracy: 0.0217\n",
            "Epoch 360/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8836 - accuracy: 0.0601 - val_loss: 1.7314 - val_accuracy: 0.0205\n",
            "Epoch 361/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8847 - accuracy: 0.0605 - val_loss: 1.7330 - val_accuracy: 0.0207\n",
            "Epoch 362/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8862 - accuracy: 0.0604 - val_loss: 1.7351 - val_accuracy: 0.0215\n",
            "Epoch 363/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8937 - accuracy: 0.0582 - val_loss: 1.7409 - val_accuracy: 0.0203\n",
            "Epoch 364/600\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.8842 - accuracy: 0.0602 - val_loss: 1.7442 - val_accuracy: 0.0207\n",
            "Epoch 365/600\n",
            "32/32 [==============================] - 1s 22ms/step - loss: 0.8902 - accuracy: 0.0591 - val_loss: 1.7312 - val_accuracy: 0.0205\n",
            "Epoch 366/600\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.8821 - accuracy: 0.0601 - val_loss: 1.7257 - val_accuracy: 0.0210\n",
            "Epoch 367/600\n",
            "32/32 [==============================] - 1s 22ms/step - loss: 0.8879 - accuracy: 0.0586 - val_loss: 1.7394 - val_accuracy: 0.0213\n",
            "Epoch 368/600\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.8857 - accuracy: 0.0597 - val_loss: 1.7290 - val_accuracy: 0.0205\n",
            "Epoch 369/600\n",
            "32/32 [==============================] - 1s 22ms/step - loss: 0.8879 - accuracy: 0.0586 - val_loss: 1.7353 - val_accuracy: 0.0207\n",
            "Epoch 370/600\n",
            "32/32 [==============================] - 1s 23ms/step - loss: 0.8761 - accuracy: 0.0615 - val_loss: 1.7372 - val_accuracy: 0.0205\n",
            "Epoch 371/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8852 - accuracy: 0.0592 - val_loss: 1.7443 - val_accuracy: 0.0203\n",
            "Epoch 372/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8837 - accuracy: 0.0608 - val_loss: 1.7357 - val_accuracy: 0.0210\n",
            "Epoch 373/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8792 - accuracy: 0.0612 - val_loss: 1.7325 - val_accuracy: 0.0210\n",
            "Epoch 374/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8740 - accuracy: 0.0616 - val_loss: 1.7456 - val_accuracy: 0.0205\n",
            "Epoch 375/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8792 - accuracy: 0.0613 - val_loss: 1.7411 - val_accuracy: 0.0210\n",
            "Epoch 376/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8730 - accuracy: 0.0627 - val_loss: 1.7406 - val_accuracy: 0.0213\n",
            "Epoch 377/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8779 - accuracy: 0.0608 - val_loss: 1.7199 - val_accuracy: 0.0213\n",
            "Epoch 378/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.8722 - accuracy: 0.0624 - val_loss: 1.7389 - val_accuracy: 0.0213\n",
            "Epoch 379/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8731 - accuracy: 0.0610 - val_loss: 1.7431 - val_accuracy: 0.0215\n",
            "Epoch 380/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8697 - accuracy: 0.0634 - val_loss: 1.7405 - val_accuracy: 0.0207\n",
            "Epoch 381/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8678 - accuracy: 0.0631 - val_loss: 1.7348 - val_accuracy: 0.0207\n",
            "Epoch 382/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.8675 - accuracy: 0.0627 - val_loss: 1.7344 - val_accuracy: 0.0215\n",
            "Epoch 383/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8676 - accuracy: 0.0624 - val_loss: 1.7448 - val_accuracy: 0.0207\n",
            "Epoch 384/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8682 - accuracy: 0.0621 - val_loss: 1.7234 - val_accuracy: 0.0207\n",
            "Epoch 385/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8664 - accuracy: 0.0631 - val_loss: 1.7305 - val_accuracy: 0.0213\n",
            "Epoch 386/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8623 - accuracy: 0.0627 - val_loss: 1.7518 - val_accuracy: 0.0203\n",
            "Epoch 387/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8613 - accuracy: 0.0636 - val_loss: 1.7348 - val_accuracy: 0.0213\n",
            "Epoch 388/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8654 - accuracy: 0.0622 - val_loss: 1.7696 - val_accuracy: 0.0188\n",
            "Epoch 389/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8679 - accuracy: 0.0624 - val_loss: 1.7293 - val_accuracy: 0.0213\n",
            "Epoch 390/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8500 - accuracy: 0.0671 - val_loss: 1.7257 - val_accuracy: 0.0217\n",
            "Epoch 391/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8482 - accuracy: 0.0668 - val_loss: 1.7359 - val_accuracy: 0.0210\n",
            "Epoch 392/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8492 - accuracy: 0.0661 - val_loss: 1.7309 - val_accuracy: 0.0210\n",
            "Epoch 393/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8637 - accuracy: 0.0642 - val_loss: 1.7399 - val_accuracy: 0.0217\n",
            "Epoch 394/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8540 - accuracy: 0.0644 - val_loss: 1.7490 - val_accuracy: 0.0210\n",
            "Epoch 395/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.8590 - accuracy: 0.0652 - val_loss: 1.7466 - val_accuracy: 0.0220\n",
            "Epoch 396/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.8579 - accuracy: 0.0644 - val_loss: 1.7313 - val_accuracy: 0.0220\n",
            "Epoch 397/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8493 - accuracy: 0.0656 - val_loss: 1.7493 - val_accuracy: 0.0203\n",
            "Epoch 398/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8505 - accuracy: 0.0654 - val_loss: 1.7473 - val_accuracy: 0.0215\n",
            "Epoch 399/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8476 - accuracy: 0.0665 - val_loss: 1.7460 - val_accuracy: 0.0210\n",
            "Epoch 400/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8516 - accuracy: 0.0655 - val_loss: 1.7427 - val_accuracy: 0.0217\n",
            "Epoch 401/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8470 - accuracy: 0.0662 - val_loss: 1.7459 - val_accuracy: 0.0217\n",
            "Epoch 402/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8392 - accuracy: 0.0679 - val_loss: 1.7554 - val_accuracy: 0.0217\n",
            "Epoch 403/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8384 - accuracy: 0.0693 - val_loss: 1.7518 - val_accuracy: 0.0207\n",
            "Epoch 404/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8392 - accuracy: 0.0678 - val_loss: 1.7610 - val_accuracy: 0.0213\n",
            "Epoch 405/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8412 - accuracy: 0.0674 - val_loss: 1.7380 - val_accuracy: 0.0207\n",
            "Epoch 406/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8408 - accuracy: 0.0683 - val_loss: 1.7364 - val_accuracy: 0.0215\n",
            "Epoch 407/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8490 - accuracy: 0.0653 - val_loss: 1.7249 - val_accuracy: 0.0213\n",
            "Epoch 408/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8326 - accuracy: 0.0702 - val_loss: 1.7464 - val_accuracy: 0.0215\n",
            "Epoch 409/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8283 - accuracy: 0.0704 - val_loss: 1.7403 - val_accuracy: 0.0210\n",
            "Epoch 410/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8309 - accuracy: 0.0697 - val_loss: 1.7391 - val_accuracy: 0.0220\n",
            "Epoch 411/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8383 - accuracy: 0.0674 - val_loss: 1.7353 - val_accuracy: 0.0210\n",
            "Epoch 412/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8361 - accuracy: 0.0680 - val_loss: 1.7417 - val_accuracy: 0.0217\n",
            "Epoch 413/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8355 - accuracy: 0.0686 - val_loss: 1.7263 - val_accuracy: 0.0215\n",
            "Epoch 414/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.8316 - accuracy: 0.0694 - val_loss: 1.7530 - val_accuracy: 0.0210\n",
            "Epoch 415/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8301 - accuracy: 0.0689 - val_loss: 1.7414 - val_accuracy: 0.0215\n",
            "Epoch 416/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8321 - accuracy: 0.0699 - val_loss: 1.7264 - val_accuracy: 0.0220\n",
            "Epoch 417/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8720 - accuracy: 0.0652 - val_loss: 1.7181 - val_accuracy: 0.0210\n",
            "Epoch 418/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8823 - accuracy: 0.0631 - val_loss: 1.7108 - val_accuracy: 0.0215\n",
            "Epoch 419/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8563 - accuracy: 0.0670 - val_loss: 1.7279 - val_accuracy: 0.0215\n",
            "Epoch 420/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8322 - accuracy: 0.0698 - val_loss: 1.7318 - val_accuracy: 0.0220\n",
            "Epoch 421/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8309 - accuracy: 0.0710 - val_loss: 1.7266 - val_accuracy: 0.0223\n",
            "Epoch 422/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8521 - accuracy: 0.0662 - val_loss: 1.7346 - val_accuracy: 0.0220\n",
            "Epoch 423/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0354 - accuracy: 0.0396 - val_loss: 1.7189 - val_accuracy: 0.0217\n",
            "Epoch 424/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.0398 - accuracy: 0.0374 - val_loss: 1.7073 - val_accuracy: 0.0207\n",
            "Epoch 425/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9949 - accuracy: 0.0441 - val_loss: 1.7005 - val_accuracy: 0.0213\n",
            "Epoch 426/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9613 - accuracy: 0.0490 - val_loss: 1.7115 - val_accuracy: 0.0215\n",
            "Epoch 427/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.9136 - accuracy: 0.0574 - val_loss: 1.7172 - val_accuracy: 0.0200\n",
            "Epoch 428/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8785 - accuracy: 0.0613 - val_loss: 1.7293 - val_accuracy: 0.0200\n",
            "Epoch 429/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8671 - accuracy: 0.0653 - val_loss: 1.7268 - val_accuracy: 0.0205\n",
            "Epoch 430/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.8465 - accuracy: 0.0681 - val_loss: 1.7375 - val_accuracy: 0.0213\n",
            "Epoch 431/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8354 - accuracy: 0.0688 - val_loss: 1.7203 - val_accuracy: 0.0220\n",
            "Epoch 432/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8394 - accuracy: 0.0681 - val_loss: 1.7267 - val_accuracy: 0.0205\n",
            "Epoch 433/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8267 - accuracy: 0.0705 - val_loss: 1.7331 - val_accuracy: 0.0215\n",
            "Epoch 434/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8224 - accuracy: 0.0705 - val_loss: 1.7430 - val_accuracy: 0.0217\n",
            "Epoch 435/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8211 - accuracy: 0.0694 - val_loss: 1.7391 - val_accuracy: 0.0210\n",
            "Epoch 436/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8218 - accuracy: 0.0709 - val_loss: 1.7433 - val_accuracy: 0.0220\n",
            "Epoch 437/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8186 - accuracy: 0.0706 - val_loss: 1.7238 - val_accuracy: 0.0215\n",
            "Epoch 438/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8119 - accuracy: 0.0736 - val_loss: 1.7483 - val_accuracy: 0.0215\n",
            "Epoch 439/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8174 - accuracy: 0.0711 - val_loss: 1.7352 - val_accuracy: 0.0213\n",
            "Epoch 440/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8172 - accuracy: 0.0711 - val_loss: 1.7227 - val_accuracy: 0.0207\n",
            "Epoch 441/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8202 - accuracy: 0.0712 - val_loss: 1.7283 - val_accuracy: 0.0217\n",
            "Epoch 442/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8098 - accuracy: 0.0734 - val_loss: 1.7104 - val_accuracy: 0.0220\n",
            "Epoch 443/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8069 - accuracy: 0.0728 - val_loss: 1.7360 - val_accuracy: 0.0210\n",
            "Epoch 444/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8078 - accuracy: 0.0733 - val_loss: 1.7314 - val_accuracy: 0.0217\n",
            "Epoch 445/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8028 - accuracy: 0.0732 - val_loss: 1.7526 - val_accuracy: 0.0230\n",
            "Epoch 446/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8334 - accuracy: 0.0678 - val_loss: 1.7371 - val_accuracy: 0.0223\n",
            "Epoch 447/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8050 - accuracy: 0.0741 - val_loss: 1.7313 - val_accuracy: 0.0223\n",
            "Epoch 448/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8102 - accuracy: 0.0716 - val_loss: 1.7514 - val_accuracy: 0.0213\n",
            "Epoch 449/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8039 - accuracy: 0.0739 - val_loss: 1.7381 - val_accuracy: 0.0217\n",
            "Epoch 450/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8076 - accuracy: 0.0731 - val_loss: 1.7464 - val_accuracy: 0.0215\n",
            "Epoch 451/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8002 - accuracy: 0.0749 - val_loss: 1.7414 - val_accuracy: 0.0225\n",
            "Epoch 452/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7994 - accuracy: 0.0756 - val_loss: 1.7369 - val_accuracy: 0.0210\n",
            "Epoch 453/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.7955 - accuracy: 0.0762 - val_loss: 1.7556 - val_accuracy: 0.0227\n",
            "Epoch 454/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7944 - accuracy: 0.0756 - val_loss: 1.7504 - val_accuracy: 0.0233\n",
            "Epoch 455/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7996 - accuracy: 0.0740 - val_loss: 1.7304 - val_accuracy: 0.0217\n",
            "Epoch 456/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7974 - accuracy: 0.0751 - val_loss: 1.7342 - val_accuracy: 0.0210\n",
            "Epoch 457/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7926 - accuracy: 0.0754 - val_loss: 1.7364 - val_accuracy: 0.0210\n",
            "Epoch 458/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.7901 - accuracy: 0.0756 - val_loss: 1.7286 - val_accuracy: 0.0203\n",
            "Epoch 459/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.7944 - accuracy: 0.0747 - val_loss: 1.7239 - val_accuracy: 0.0215\n",
            "Epoch 460/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7891 - accuracy: 0.0760 - val_loss: 1.7330 - val_accuracy: 0.0213\n",
            "Epoch 461/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7886 - accuracy: 0.0753 - val_loss: 1.7311 - val_accuracy: 0.0225\n",
            "Epoch 462/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7873 - accuracy: 0.0757 - val_loss: 1.7428 - val_accuracy: 0.0203\n",
            "Epoch 463/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7911 - accuracy: 0.0754 - val_loss: 1.7359 - val_accuracy: 0.0215\n",
            "Epoch 464/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7827 - accuracy: 0.0763 - val_loss: 1.7398 - val_accuracy: 0.0198\n",
            "Epoch 465/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7880 - accuracy: 0.0759 - val_loss: 1.7401 - val_accuracy: 0.0220\n",
            "Epoch 466/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7861 - accuracy: 0.0764 - val_loss: 1.7299 - val_accuracy: 0.0215\n",
            "Epoch 467/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7827 - accuracy: 0.0774 - val_loss: 1.7387 - val_accuracy: 0.0210\n",
            "Epoch 468/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7852 - accuracy: 0.0768 - val_loss: 1.7418 - val_accuracy: 0.0210\n",
            "Epoch 469/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7789 - accuracy: 0.0783 - val_loss: 1.7355 - val_accuracy: 0.0217\n",
            "Epoch 470/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7757 - accuracy: 0.0769 - val_loss: 1.7410 - val_accuracy: 0.0233\n",
            "Epoch 471/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7792 - accuracy: 0.0770 - val_loss: 1.7511 - val_accuracy: 0.0205\n",
            "Epoch 472/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7737 - accuracy: 0.0785 - val_loss: 1.7412 - val_accuracy: 0.0223\n",
            "Epoch 473/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.7755 - accuracy: 0.0783 - val_loss: 1.7567 - val_accuracy: 0.0210\n",
            "Epoch 474/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.7773 - accuracy: 0.0774 - val_loss: 1.7442 - val_accuracy: 0.0213\n",
            "Epoch 475/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7683 - accuracy: 0.0798 - val_loss: 1.7538 - val_accuracy: 0.0210\n",
            "Epoch 476/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.7754 - accuracy: 0.0784 - val_loss: 1.7488 - val_accuracy: 0.0213\n",
            "Epoch 477/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.7699 - accuracy: 0.0786 - val_loss: 1.7541 - val_accuracy: 0.0205\n",
            "Epoch 478/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7702 - accuracy: 0.0791 - val_loss: 1.7459 - val_accuracy: 0.0213\n",
            "Epoch 479/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7623 - accuracy: 0.0806 - val_loss: 1.7536 - val_accuracy: 0.0205\n",
            "Epoch 480/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.7685 - accuracy: 0.0802 - val_loss: 1.7397 - val_accuracy: 0.0210\n",
            "Epoch 481/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.7594 - accuracy: 0.0803 - val_loss: 1.7537 - val_accuracy: 0.0213\n",
            "Epoch 482/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7694 - accuracy: 0.0783 - val_loss: 1.7470 - val_accuracy: 0.0210\n",
            "Epoch 483/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.7628 - accuracy: 0.0791 - val_loss: 1.7544 - val_accuracy: 0.0207\n",
            "Epoch 484/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.7609 - accuracy: 0.0808 - val_loss: 1.7464 - val_accuracy: 0.0207\n",
            "Epoch 485/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7591 - accuracy: 0.0809 - val_loss: 1.7457 - val_accuracy: 0.0213\n",
            "Epoch 486/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7600 - accuracy: 0.0821 - val_loss: 1.7496 - val_accuracy: 0.0215\n",
            "Epoch 487/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7610 - accuracy: 0.0809 - val_loss: 1.7400 - val_accuracy: 0.0217\n",
            "Epoch 488/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7527 - accuracy: 0.0824 - val_loss: 1.7408 - val_accuracy: 0.0215\n",
            "Epoch 489/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7599 - accuracy: 0.0799 - val_loss: 1.7554 - val_accuracy: 0.0215\n",
            "Epoch 490/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7552 - accuracy: 0.0816 - val_loss: 1.7432 - val_accuracy: 0.0205\n",
            "Epoch 491/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7565 - accuracy: 0.0804 - val_loss: 1.7509 - val_accuracy: 0.0205\n",
            "Epoch 492/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.7515 - accuracy: 0.0826 - val_loss: 1.7670 - val_accuracy: 0.0213\n",
            "Epoch 493/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7559 - accuracy: 0.0815 - val_loss: 1.7616 - val_accuracy: 0.0213\n",
            "Epoch 494/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7558 - accuracy: 0.0820 - val_loss: 1.7554 - val_accuracy: 0.0207\n",
            "Epoch 495/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7510 - accuracy: 0.0831 - val_loss: 1.7569 - val_accuracy: 0.0207\n",
            "Epoch 496/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7493 - accuracy: 0.0814 - val_loss: 1.7431 - val_accuracy: 0.0217\n",
            "Epoch 497/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7481 - accuracy: 0.0833 - val_loss: 1.7742 - val_accuracy: 0.0210\n",
            "Epoch 498/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.7457 - accuracy: 0.0831 - val_loss: 1.7678 - val_accuracy: 0.0203\n",
            "Epoch 499/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7417 - accuracy: 0.0843 - val_loss: 1.7644 - val_accuracy: 0.0215\n",
            "Epoch 500/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.7346 - accuracy: 0.0855 - val_loss: 1.7597 - val_accuracy: 0.0213\n",
            "Epoch 501/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7415 - accuracy: 0.0846 - val_loss: 1.7620 - val_accuracy: 0.0210\n",
            "Epoch 502/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7427 - accuracy: 0.0829 - val_loss: 1.7551 - val_accuracy: 0.0217\n",
            "Epoch 503/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.7470 - accuracy: 0.0821 - val_loss: 1.7382 - val_accuracy: 0.0213\n",
            "Epoch 504/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7375 - accuracy: 0.0847 - val_loss: 1.7520 - val_accuracy: 0.0223\n",
            "Epoch 505/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7386 - accuracy: 0.0844 - val_loss: 1.7589 - val_accuracy: 0.0205\n",
            "Epoch 506/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7490 - accuracy: 0.0829 - val_loss: 1.7608 - val_accuracy: 0.0220\n",
            "Epoch 507/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7383 - accuracy: 0.0842 - val_loss: 1.7634 - val_accuracy: 0.0203\n",
            "Epoch 508/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.7403 - accuracy: 0.0848 - val_loss: 1.7711 - val_accuracy: 0.0215\n",
            "Epoch 509/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7326 - accuracy: 0.0867 - val_loss: 1.7595 - val_accuracy: 0.0200\n",
            "Epoch 510/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.7378 - accuracy: 0.0856 - val_loss: 1.7673 - val_accuracy: 0.0225\n",
            "Epoch 511/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.7324 - accuracy: 0.0856 - val_loss: 1.7636 - val_accuracy: 0.0225\n",
            "Epoch 512/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.8081 - accuracy: 0.0732 - val_loss: 1.7987 - val_accuracy: 0.0220\n",
            "Epoch 513/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.8125 - accuracy: 0.0721 - val_loss: 1.7442 - val_accuracy: 0.0210\n",
            "Epoch 514/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8843 - accuracy: 0.0618 - val_loss: 1.7821 - val_accuracy: 0.0225\n",
            "Epoch 515/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.8082 - accuracy: 0.0738 - val_loss: 1.7696 - val_accuracy: 0.0223\n",
            "Epoch 516/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.8079 - accuracy: 0.0742 - val_loss: 1.7552 - val_accuracy: 0.0203\n",
            "Epoch 517/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.9090 - accuracy: 0.0568 - val_loss: 1.7458 - val_accuracy: 0.0213\n",
            "Epoch 518/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.8343 - accuracy: 0.0697 - val_loss: 1.7388 - val_accuracy: 0.0217\n",
            "Epoch 519/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.7947 - accuracy: 0.0769 - val_loss: 1.7314 - val_accuracy: 0.0215\n",
            "Epoch 520/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.7778 - accuracy: 0.0801 - val_loss: 1.7588 - val_accuracy: 0.0220\n",
            "Epoch 521/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.7937 - accuracy: 0.0770 - val_loss: 1.7306 - val_accuracy: 0.0225\n",
            "Epoch 522/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.8096 - accuracy: 0.0744 - val_loss: 1.7401 - val_accuracy: 0.0215\n",
            "Epoch 523/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7635 - accuracy: 0.0812 - val_loss: 1.7491 - val_accuracy: 0.0217\n",
            "Epoch 524/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7497 - accuracy: 0.0833 - val_loss: 1.7609 - val_accuracy: 0.0230\n",
            "Epoch 525/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7419 - accuracy: 0.0849 - val_loss: 1.7615 - val_accuracy: 0.0217\n",
            "Epoch 526/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.7393 - accuracy: 0.0846 - val_loss: 1.7460 - val_accuracy: 0.0213\n",
            "Epoch 527/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7318 - accuracy: 0.0858 - val_loss: 1.7648 - val_accuracy: 0.0227\n",
            "Epoch 528/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.7317 - accuracy: 0.0864 - val_loss: 1.7595 - val_accuracy: 0.0215\n",
            "Epoch 529/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7276 - accuracy: 0.0871 - val_loss: 1.7585 - val_accuracy: 0.0220\n",
            "Epoch 530/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7300 - accuracy: 0.0859 - val_loss: 1.7687 - val_accuracy: 0.0217\n",
            "Epoch 531/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7405 - accuracy: 0.0834 - val_loss: 1.7622 - val_accuracy: 0.0207\n",
            "Epoch 532/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7266 - accuracy: 0.0861 - val_loss: 1.7789 - val_accuracy: 0.0213\n",
            "Epoch 533/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7359 - accuracy: 0.0856 - val_loss: 1.7691 - val_accuracy: 0.0215\n",
            "Epoch 534/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7187 - accuracy: 0.0891 - val_loss: 1.7586 - val_accuracy: 0.0230\n",
            "Epoch 535/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7181 - accuracy: 0.0886 - val_loss: 1.7609 - val_accuracy: 0.0217\n",
            "Epoch 536/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.7263 - accuracy: 0.0865 - val_loss: 1.7666 - val_accuracy: 0.0213\n",
            "Epoch 537/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7115 - accuracy: 0.0896 - val_loss: 1.7533 - val_accuracy: 0.0227\n",
            "Epoch 538/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7190 - accuracy: 0.0889 - val_loss: 1.7700 - val_accuracy: 0.0207\n",
            "Epoch 539/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7119 - accuracy: 0.0889 - val_loss: 1.7618 - val_accuracy: 0.0220\n",
            "Epoch 540/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7147 - accuracy: 0.0888 - val_loss: 1.7717 - val_accuracy: 0.0220\n",
            "Epoch 541/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7206 - accuracy: 0.0879 - val_loss: 1.7766 - val_accuracy: 0.0220\n",
            "Epoch 542/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7099 - accuracy: 0.0908 - val_loss: 1.7713 - val_accuracy: 0.0213\n",
            "Epoch 543/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.7124 - accuracy: 0.0894 - val_loss: 1.7763 - val_accuracy: 0.0210\n",
            "Epoch 544/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7155 - accuracy: 0.0889 - val_loss: 1.7507 - val_accuracy: 0.0217\n",
            "Epoch 545/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7087 - accuracy: 0.0901 - val_loss: 1.7491 - val_accuracy: 0.0220\n",
            "Epoch 546/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7043 - accuracy: 0.0907 - val_loss: 1.7737 - val_accuracy: 0.0205\n",
            "Epoch 547/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7110 - accuracy: 0.0894 - val_loss: 1.7592 - val_accuracy: 0.0230\n",
            "Epoch 548/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7042 - accuracy: 0.0909 - val_loss: 1.8080 - val_accuracy: 0.0227\n",
            "Epoch 549/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.7040 - accuracy: 0.0908 - val_loss: 1.7507 - val_accuracy: 0.0225\n",
            "Epoch 550/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7024 - accuracy: 0.0904 - val_loss: 1.7601 - val_accuracy: 0.0225\n",
            "Epoch 551/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7077 - accuracy: 0.0909 - val_loss: 1.7542 - val_accuracy: 0.0220\n",
            "Epoch 552/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7034 - accuracy: 0.0909 - val_loss: 1.7672 - val_accuracy: 0.0217\n",
            "Epoch 553/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6972 - accuracy: 0.0919 - val_loss: 1.7628 - val_accuracy: 0.0223\n",
            "Epoch 554/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.7032 - accuracy: 0.0908 - val_loss: 1.7572 - val_accuracy: 0.0220\n",
            "Epoch 555/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.6989 - accuracy: 0.0916 - val_loss: 1.7599 - val_accuracy: 0.0207\n",
            "Epoch 556/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.6985 - accuracy: 0.0919 - val_loss: 1.7607 - val_accuracy: 0.0213\n",
            "Epoch 557/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.6951 - accuracy: 0.0916 - val_loss: 1.7520 - val_accuracy: 0.0215\n",
            "Epoch 558/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.6958 - accuracy: 0.0921 - val_loss: 1.7781 - val_accuracy: 0.0210\n",
            "Epoch 559/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.7040 - accuracy: 0.0916 - val_loss: 1.7733 - val_accuracy: 0.0210\n",
            "Epoch 560/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.6967 - accuracy: 0.0919 - val_loss: 1.7619 - val_accuracy: 0.0217\n",
            "Epoch 561/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.6909 - accuracy: 0.0932 - val_loss: 1.7768 - val_accuracy: 0.0213\n",
            "Epoch 562/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.6917 - accuracy: 0.0936 - val_loss: 1.7624 - val_accuracy: 0.0215\n",
            "Epoch 563/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.6988 - accuracy: 0.0915 - val_loss: 1.7835 - val_accuracy: 0.0213\n",
            "Epoch 564/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.6929 - accuracy: 0.0933 - val_loss: 1.7682 - val_accuracy: 0.0217\n",
            "Epoch 565/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.6846 - accuracy: 0.0943 - val_loss: 1.7724 - val_accuracy: 0.0220\n",
            "Epoch 566/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.6885 - accuracy: 0.0938 - val_loss: 1.7745 - val_accuracy: 0.0195\n",
            "Epoch 567/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.6915 - accuracy: 0.0936 - val_loss: 1.7779 - val_accuracy: 0.0217\n",
            "Epoch 568/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.6891 - accuracy: 0.0938 - val_loss: 1.7545 - val_accuracy: 0.0220\n",
            "Epoch 569/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.6952 - accuracy: 0.0931 - val_loss: 1.7602 - val_accuracy: 0.0207\n",
            "Epoch 570/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.6843 - accuracy: 0.0933 - val_loss: 1.7532 - val_accuracy: 0.0220\n",
            "Epoch 571/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.6946 - accuracy: 0.0919 - val_loss: 1.7666 - val_accuracy: 0.0213\n",
            "Epoch 572/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.6808 - accuracy: 0.0957 - val_loss: 1.7683 - val_accuracy: 0.0213\n",
            "Epoch 573/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.6844 - accuracy: 0.0949 - val_loss: 1.7646 - val_accuracy: 0.0213\n",
            "Epoch 574/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.6805 - accuracy: 0.0961 - val_loss: 1.7673 - val_accuracy: 0.0207\n",
            "Epoch 575/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.6791 - accuracy: 0.0954 - val_loss: 1.7645 - val_accuracy: 0.0213\n",
            "Epoch 576/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.6816 - accuracy: 0.0956 - val_loss: 1.7814 - val_accuracy: 0.0217\n",
            "Epoch 577/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.6861 - accuracy: 0.0953 - val_loss: 1.7548 - val_accuracy: 0.0217\n",
            "Epoch 578/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.6801 - accuracy: 0.0969 - val_loss: 1.7666 - val_accuracy: 0.0223\n",
            "Epoch 579/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.6798 - accuracy: 0.0964 - val_loss: 1.7563 - val_accuracy: 0.0225\n",
            "Epoch 580/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.6693 - accuracy: 0.0981 - val_loss: 1.7653 - val_accuracy: 0.0217\n",
            "Epoch 581/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.6743 - accuracy: 0.0967 - val_loss: 1.7655 - val_accuracy: 0.0225\n",
            "Epoch 582/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.6751 - accuracy: 0.0967 - val_loss: 1.7599 - val_accuracy: 0.0217\n",
            "Epoch 583/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6718 - accuracy: 0.0974 - val_loss: 1.7490 - val_accuracy: 0.0220\n",
            "Epoch 584/600\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.6753 - accuracy: 0.0970 - val_loss: 1.7526 - val_accuracy: 0.0210\n",
            "Epoch 585/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.6720 - accuracy: 0.0978 - val_loss: 1.7653 - val_accuracy: 0.0210\n",
            "Epoch 586/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.6714 - accuracy: 0.0973 - val_loss: 1.7627 - val_accuracy: 0.0225\n",
            "Epoch 587/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.6776 - accuracy: 0.0959 - val_loss: 1.7475 - val_accuracy: 0.0215\n",
            "Epoch 588/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.6691 - accuracy: 0.0972 - val_loss: 1.7508 - val_accuracy: 0.0220\n",
            "Epoch 589/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.6653 - accuracy: 0.0988 - val_loss: 1.7685 - val_accuracy: 0.0213\n",
            "Epoch 590/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.6662 - accuracy: 0.0983 - val_loss: 1.7512 - val_accuracy: 0.0207\n",
            "Epoch 591/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.6686 - accuracy: 0.0972 - val_loss: 1.7568 - val_accuracy: 0.0217\n",
            "Epoch 592/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.6611 - accuracy: 0.0986 - val_loss: 1.7716 - val_accuracy: 0.0215\n",
            "Epoch 593/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.6663 - accuracy: 0.0989 - val_loss: 1.7698 - val_accuracy: 0.0213\n",
            "Epoch 594/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.6714 - accuracy: 0.0975 - val_loss: 1.7672 - val_accuracy: 0.0225\n",
            "Epoch 595/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.6609 - accuracy: 0.0986 - val_loss: 1.7595 - val_accuracy: 0.0225\n",
            "Epoch 596/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.6691 - accuracy: 0.0983 - val_loss: 1.7528 - val_accuracy: 0.0217\n",
            "Epoch 597/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.6598 - accuracy: 0.0997 - val_loss: 1.7633 - val_accuracy: 0.0213\n",
            "Epoch 598/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.6633 - accuracy: 0.0983 - val_loss: 1.7742 - val_accuracy: 0.0220\n",
            "Epoch 599/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.6576 - accuracy: 0.1000 - val_loss: 1.7662 - val_accuracy: 0.0217\n",
            "Epoch 600/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.6631 - accuracy: 0.0993 - val_loss: 1.7664 - val_accuracy: 0.0195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "training_model = load_model('training_model.h5')\n",
        "encoder_inputs = training_model.input[0]\n",
        "encoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "metadata": {
        "id": "OXkoE1VCrclq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 256\n",
        "decoder_state_input_hidden = Input(shape=(latent_dim,))\n",
        "decoder_state_input_cell = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]"
      ],
      "metadata": {
        "id": "Sn4iy3hBrjQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_hidden, state_cell]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "metadata": {
        "id": "WfCHnz_Zrmfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
      ],
      "metadata": {
        "id": "LYoERHtDrpKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST5NJzSwJlDB"
      },
      "source": [
        "def decode_response(test_input):\n",
        "    #Getting the output states to pass into the decoder\n",
        "    states_value = encoder_model.predict(test_input)\n",
        "    #Generating empty target sequence of length 1\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    #Setting the first token of target sequence with the start token\n",
        "    target_seq[0, 0, target_features_dict['<START>']] = 1.\n",
        "    \n",
        "    #A variable to store our response word by word\n",
        "    decoded_sentence = ''\n",
        "    \n",
        "    stop_condition = False\n",
        "    while not stop_condition:\n",
        "      #Predicting output tokens with probabilities and states\n",
        "      output_tokens, hidden_state, cell_state = decoder_model.predict([target_seq] + states_value)\n",
        "#Choosing the one with highest probability\n",
        "      sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "      sampled_token = reverse_target_features_dict[sampled_token_index]\n",
        "      decoded_sentence += \" \" + sampled_token\n",
        "#Stop if hit max length or found the stop token\n",
        "      if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n",
        "        stop_condition = True\n",
        "#Update the target sequence\n",
        "      target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "      target_seq[0, 0, sampled_token_index] = 1.\n",
        "      #Update states\n",
        "      states_value = [hidden_state, cell_state]\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JTKCjKVJ92i",
        "outputId": "d5d0378b-3527-4be2-dbbe-a88699fdec2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "class ChatBot:\n",
        "  negative_responses = (\"no\", \"nope\", \"nah\", \"naw\", \"not a chance\", \"sorry\")\n",
        "  exit_commands = (\"quit\", \"pause\", \"exit\", \"goodbye\", \"bye\", \"later\", \"stop\")\n",
        "#Method to start the conversation\n",
        "  def start_chat(self):\n",
        "    user_response = input(\"Hi, I'm a chatbot trained on random dialogs. Would you like to chat with me?\\n\")\n",
        "    \n",
        "    if user_response in self.negative_responses:\n",
        "      print(\"Ok, have a great day!\")\n",
        "      return\n",
        "    self.chat(user_response)\n",
        "#Method to handle the conversation\n",
        "  def chat(self, reply):\n",
        "    while not self.make_exit(reply):\n",
        "      reply = input(self.generate_response(reply)+\"\\n\")\n",
        "    \n",
        "  #Method to convert user input into a matrix\n",
        "  def string_to_matrix(self, user_input):\n",
        "    tokens = re.findall(r\"[\\w']+|[^\\s\\w]\", user_input)\n",
        "    user_input_matrix = np.zeros(\n",
        "      (1, max_encoder_seq_length, num_encoder_tokens),\n",
        "      dtype='float32')\n",
        "    for timestep, token in enumerate(tokens):\n",
        "      if token in input_features_dict:\n",
        "        user_input_matrix[0, timestep, input_features_dict[token]] = 1.\n",
        "    return user_input_matrix\n",
        "  \n",
        "  #Method that will create a response using seq2seq model we built\n",
        "  def generate_response(self, user_input):\n",
        "    input_matrix = self.string_to_matrix(user_input)\n",
        "    chatbot_response = decode_response(input_matrix)\n",
        "    #Remove <START> and <END> tokens from chatbot_response\n",
        "    chatbot_response = chatbot_response.replace(\"<START>\",'')\n",
        "    chatbot_response = chatbot_response.replace(\"<END>\",'')\n",
        "    return chatbot_response\n",
        "#Method to check for exit commands\n",
        "  def make_exit(self, reply):\n",
        "    for exit_command in self.exit_commands:\n",
        "      if exit_command in reply:\n",
        "        print(\"Ok, have a great day!\")\n",
        "        return True\n",
        "    return False\n",
        "  \n",
        "chatbot = ChatBot()\n",
        "chatbot.start_chat()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi, I'm a chatbot trained on random dialogs. Would you like to chat with me?\n",
            "yes\n",
            "1/1 [==============================] - 0s 365ms/step\n",
            "1/1 [==============================] - 0s 339ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            " let me know you you you \n",
            "what?\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            " vim \n",
            "?\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            " any \n",
            "Any what?\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            " any \n",
            "ok\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            " ok \n",
            "nice\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            " nice what type you you \n",
            "who are you?\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            " the oss softwares softwares are you you \n",
            "hi\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            " hi there how are you \n",
            "fine\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            " westworld is good intelligence you you a a to \n",
            "are you a bot?\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            " any \n",
            "bot?\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            " any \n",
            "any\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            " i m trying to to the the \n",
            "yes\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            " let me know you you you \n",
            "my name is Toti\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            " i m 22 amazed this this t me you you you you you you\n",
            "hi there\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            " hi there yes the the to to \n",
            "i m fine\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            " storm the \n",
            "i m trying to learn ukulele\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            " exactly incredibly becoming to \n",
            "okay, bye\n",
            "Ok, have a great day!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7J5OMxJKEDK",
        "outputId": "008db9fd-b885-4bd6-ebb0-d86cd01d8825",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "chatbot.start_chat()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi, I'm a chatbot trained on random dialogs. Would you like to chat with me?\n",
            "hi there\n",
            " hi there how are you today \n",
            "i m fine\n",
            " everything is fine on this side \n",
            "nice\n",
            " how is work going today \n",
            "all is good\n",
            " i m trying to learn like with the ukulele \n",
            "okay bye\n",
            "Ok, have a great day!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN9jd7lQqtbq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}